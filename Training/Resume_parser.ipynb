{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume_parser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYxnH3dILdq7",
        "outputId": "5c5bd58e-6f50-4895-fa9d-1adffe48074b"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.19.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRUpTTAiLs_j",
        "outputId": "7ad61da8-8a04-40e2-96dc-f35869d0e68a"
      },
      "source": [
        "!git clone https://github.com/laxmimerit/Resume-and-CV-Summarization-and-Parsing-with-Spacy-in-Python"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Resume-and-CV-Summarization-and-Parsing-with-Spacy-in-Python'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 34 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk0hCgeYxWBj"
      },
      "source": [
        "import spacy\n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CxiOYmAxhNO"
      },
      "source": [
        "train_data = pickle.load(open('Resume-and-CV-Summarization-and-Parsing-with-Spacy-in-Python/train_data.pkl','rb'))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJsPKh_OMVbc",
        "outputId": "f6362f99-27be-49c9-e291-108364d7a2c0"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [(1749, 1755, 'Companies worked at'),\n",
              "   (1696, 1702, 'Companies worked at'),\n",
              "   (1417, 1423, 'Companies worked at'),\n",
              "   (1356, 1793, 'Skills'),\n",
              "   (1209, 1215, 'Companies worked at'),\n",
              "   (1136, 1248, 'Skills'),\n",
              "   (928, 932, 'Graduation Year'),\n",
              "   (858, 889, 'College Name'),\n",
              "   (821, 856, 'Degree'),\n",
              "   (787, 791, 'Graduation Year'),\n",
              "   (744, 750, 'Companies worked at'),\n",
              "   (722, 742, 'Designation'),\n",
              "   (658, 664, 'Companies worked at'),\n",
              "   (640, 656, 'Designation'),\n",
              "   (574, 580, 'Companies worked at'),\n",
              "   (555, 573, 'Designation'),\n",
              "   (470, 493, 'Companies worked at'),\n",
              "   (444, 469, 'Designation'),\n",
              "   (308, 314, 'Companies worked at'),\n",
              "   (234, 240, 'Companies worked at'),\n",
              "   (175, 198, 'Companies worked at'),\n",
              "   (93, 137, 'Email Address'),\n",
              "   (39, 48, 'Location'),\n",
              "   (13, 38, 'Designation'),\n",
              "   (0, 12, 'Name')]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GPaZV-zMfdm"
      },
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "def train_model(train_data):\n",
        "  if 'ner' not in nlp.pipe_names:\n",
        "    ner = nlp.create_pipe('ner')\n",
        "    nlp.add_pipe(ner,last = True)\n",
        "\n",
        "\n",
        "  for _, annotations in train_data:\n",
        "    for ent in annotations['entities']:\n",
        "       ner.add_label(ent[2])\n",
        "\n",
        "\n",
        "  other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "  with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "    for itn in range(100):\n",
        "      print('Starting iteration ' + str(itn))\n",
        "      random.shuffle(train_data)\n",
        "      losses = {}\n",
        "      index = 0\n",
        "      for text, annotations in train_data:\n",
        "        try:\n",
        "          nlp.update(\n",
        "              [text],\n",
        "              [annotations],  \n",
        "              drop=0.2,\n",
        "              sgd = optimizer, \n",
        "              losses=losses)\n",
        "        except Exception as e:\n",
        "          pass\n",
        "          # print(e)\n",
        "      print(\"Losses\", losses)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhoLz8roSy-e",
        "outputId": "f508a7e6-aa0b-4856-9341-5cffe4a55d0c"
      },
      "source": [
        "train_model(train_data)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting iteration 0\n",
            "Losses {'ner': 11188.075537547229}\n",
            "Starting iteration 1\n",
            "Losses {'ner': 9351.713550926772}\n",
            "Starting iteration 2\n",
            "Losses {'ner': 7877.335484156807}\n",
            "Starting iteration 3\n",
            "Losses {'ner': 6752.00394480316}\n",
            "Starting iteration 4\n",
            "Losses {'ner': 6021.327174717933}\n",
            "Starting iteration 5\n",
            "Losses {'ner': 6262.11465713919}\n",
            "Starting iteration 6\n",
            "Losses {'ner': 6299.319370892419}\n",
            "Starting iteration 7\n",
            "Losses {'ner': 6442.310302782612}\n",
            "Starting iteration 8\n",
            "Losses {'ner': 5626.022717197389}\n",
            "Starting iteration 9\n",
            "Losses {'ner': 5097.292289193935}\n",
            "Starting iteration 10\n",
            "Losses {'ner': 5126.778010136023}\n",
            "Starting iteration 11\n",
            "Losses {'ner': 4579.811423217832}\n",
            "Starting iteration 12\n",
            "Losses {'ner': 4911.932135708262}\n",
            "Starting iteration 13\n",
            "Losses {'ner': 4361.50448907307}\n",
            "Starting iteration 14\n",
            "Losses {'ner': 3873.0201539046757}\n",
            "Starting iteration 15\n",
            "Losses {'ner': 4039.465545267248}\n",
            "Starting iteration 16\n",
            "Losses {'ner': 3671.247317843503}\n",
            "Starting iteration 17\n",
            "Losses {'ner': 3034.6840088459107}\n",
            "Starting iteration 18\n",
            "Losses {'ner': 3108.2429290498117}\n",
            "Starting iteration 19\n",
            "Losses {'ner': 3908.409090219719}\n",
            "Starting iteration 20\n",
            "Losses {'ner': 2965.9838248628726}\n",
            "Starting iteration 21\n",
            "Losses {'ner': 3582.7090543567465}\n",
            "Starting iteration 22\n",
            "Losses {'ner': 2888.936586090885}\n",
            "Starting iteration 23\n",
            "Losses {'ner': 2805.154733473691}\n",
            "Starting iteration 24\n",
            "Losses {'ner': 3813.4219844172458}\n",
            "Starting iteration 25\n",
            "Losses {'ner': 2597.52295607965}\n",
            "Starting iteration 26\n",
            "Losses {'ner': 2831.1016940702916}\n",
            "Starting iteration 27\n",
            "Losses {'ner': 3595.1411652002303}\n",
            "Starting iteration 28\n",
            "Losses {'ner': 2569.8856929535345}\n",
            "Starting iteration 29\n",
            "Losses {'ner': 2683.0641849875465}\n",
            "Starting iteration 30\n",
            "Losses {'ner': 2315.9112318200596}\n",
            "Starting iteration 31\n",
            "Losses {'ner': 2200.246191213867}\n",
            "Starting iteration 32\n",
            "Losses {'ner': 2444.478924437669}\n",
            "Starting iteration 33\n",
            "Losses {'ner': 1843.2413182813175}\n",
            "Starting iteration 34\n",
            "Losses {'ner': 2396.082818331222}\n",
            "Starting iteration 35\n",
            "Losses {'ner': 2769.8764569202795}\n",
            "Starting iteration 36\n",
            "Losses {'ner': 2202.398128577036}\n",
            "Starting iteration 37\n",
            "Losses {'ner': 1946.7849132827298}\n",
            "Starting iteration 38\n",
            "Losses {'ner': 2120.986931703706}\n",
            "Starting iteration 39\n",
            "Losses {'ner': 2242.3872353553397}\n",
            "Starting iteration 40\n",
            "Losses {'ner': 1863.5638489628925}\n",
            "Starting iteration 41\n",
            "Losses {'ner': 1902.7848298456797}\n",
            "Starting iteration 42\n",
            "Losses {'ner': 1837.5270597315016}\n",
            "Starting iteration 43\n",
            "Losses {'ner': 1896.1959447034087}\n",
            "Starting iteration 44\n",
            "Losses {'ner': 2010.2930386418302}\n",
            "Starting iteration 45\n",
            "Losses {'ner': 1832.4403956189672}\n",
            "Starting iteration 46\n",
            "Losses {'ner': 2239.430816549894}\n",
            "Starting iteration 47\n",
            "Losses {'ner': 1839.9281487139503}\n",
            "Starting iteration 48\n",
            "Losses {'ner': 1493.9266035943015}\n",
            "Starting iteration 49\n",
            "Losses {'ner': 2087.382713913857}\n",
            "Starting iteration 50\n",
            "Losses {'ner': 1742.7934716346579}\n",
            "Starting iteration 51\n",
            "Losses {'ner': 1484.0638795324303}\n",
            "Starting iteration 52\n",
            "Losses {'ner': 1847.4069845425317}\n",
            "Starting iteration 53\n",
            "Losses {'ner': 1984.7182620569388}\n",
            "Starting iteration 54\n",
            "Losses {'ner': 2096.558180420167}\n",
            "Starting iteration 55\n",
            "Losses {'ner': 1554.7614008615478}\n",
            "Starting iteration 56\n",
            "Losses {'ner': 1677.463127467745}\n",
            "Starting iteration 57\n",
            "Losses {'ner': 1550.1071407521758}\n",
            "Starting iteration 58\n",
            "Losses {'ner': 1451.2292671963544}\n",
            "Starting iteration 59\n",
            "Losses {'ner': 1722.450830774596}\n",
            "Starting iteration 60\n",
            "Losses {'ner': 1763.9204734721388}\n",
            "Starting iteration 61\n",
            "Losses {'ner': 1869.5818588019542}\n",
            "Starting iteration 62\n",
            "Losses {'ner': 1278.6504102756526}\n",
            "Starting iteration 63\n",
            "Losses {'ner': 1007.426049440136}\n",
            "Starting iteration 64\n",
            "Losses {'ner': 1251.2268220117644}\n",
            "Starting iteration 65\n",
            "Losses {'ner': 1466.3266778315692}\n",
            "Starting iteration 66\n",
            "Losses {'ner': 1320.0240614048419}\n",
            "Starting iteration 67\n",
            "Losses {'ner': 1371.409017670429}\n",
            "Starting iteration 68\n",
            "Losses {'ner': 1315.5667007063814}\n",
            "Starting iteration 69\n",
            "Losses {'ner': 1004.0847008758271}\n",
            "Starting iteration 70\n",
            "Losses {'ner': 997.0963392916681}\n",
            "Starting iteration 71\n",
            "Losses {'ner': 1085.3077445775518}\n",
            "Starting iteration 72\n",
            "Losses {'ner': 912.1559645401782}\n",
            "Starting iteration 73\n",
            "Losses {'ner': 1580.0019609585802}\n",
            "Starting iteration 74\n",
            "Losses {'ner': 966.522206257106}\n",
            "Starting iteration 75\n",
            "Losses {'ner': 858.5680510921745}\n",
            "Starting iteration 76\n",
            "Losses {'ner': 1303.4703703062235}\n",
            "Starting iteration 77\n",
            "Losses {'ner': 1120.4798376014303}\n",
            "Starting iteration 78\n",
            "Losses {'ner': 1040.3822395457705}\n",
            "Starting iteration 79\n",
            "Losses {'ner': 1214.735671330846}\n",
            "Starting iteration 80\n",
            "Losses {'ner': 1018.5629874324765}\n",
            "Starting iteration 81\n",
            "Losses {'ner': 884.1488073226706}\n",
            "Starting iteration 82\n",
            "Losses {'ner': 702.8151926935091}\n",
            "Starting iteration 83\n",
            "Losses {'ner': 793.7018691637275}\n",
            "Starting iteration 84\n",
            "Losses {'ner': 943.6904911361576}\n",
            "Starting iteration 85\n",
            "Losses {'ner': 969.861398765626}\n",
            "Starting iteration 86\n",
            "Losses {'ner': 758.152159115659}\n",
            "Starting iteration 87\n",
            "Losses {'ner': 1127.41308464451}\n",
            "Starting iteration 88\n",
            "Losses {'ner': 1303.0078042321668}\n",
            "Starting iteration 89\n",
            "Losses {'ner': 935.3660498783428}\n",
            "Starting iteration 90\n",
            "Losses {'ner': 869.1522740431544}\n",
            "Starting iteration 91\n",
            "Losses {'ner': 724.8149030851928}\n",
            "Starting iteration 92\n",
            "Losses {'ner': 801.9249598615424}\n",
            "Starting iteration 93\n",
            "Losses {'ner': 606.2106856588083}\n",
            "Starting iteration 94\n",
            "Losses {'ner': 660.9887215772158}\n",
            "Starting iteration 95\n",
            "Losses {'ner': 666.5198717540437}\n",
            "Starting iteration 96\n",
            "Losses {'ner': 617.8886700393064}\n",
            "Starting iteration 97\n",
            "Losses {'ner': 700.2972470974007}\n",
            "Starting iteration 98\n",
            "Losses {'ner': 983.0974504419058}\n",
            "Starting iteration 99\n",
            "Losses {'ner': 655.9282006158157}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dz-MUQqTovh"
      },
      "source": [
        "nlp.to_disk('CV_parser_model')"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw6XpCymxbzI"
      },
      "source": [
        "nlp_model = spacy.load('nlp_model')"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n2Wn1BnvwTA",
        "outputId": "686dbec5-fe4a-440b-bf93-f34f5bd6e9c3"
      },
      "source": [
        "doc = nlp_model(train_data[0][0])\n",
        "for ent in doc.ents:\n",
        "  print(f'{ent.label_.upper():{30}}-{ent.text}')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME                          -Pratik Vaidya\n",
            "LOCATION                      -Pune\n",
            "DEGREE                        -Btech\n",
            "COLLEGE NAME                  -Maharashtra Institute of Technology\n",
            "GRADUATION YEAR               -2016\n",
            "GRADUATION YEAR               -2013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0yl-6rawxZJ",
        "outputId": "d7235448-049b-4371-a9a3-8c570fdc2e30"
      },
      "source": [
        "!pip install PyMuPDF"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyMuPDF\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/22/d59001c1d7df4a1839924c0ca67a3313cbcdadb7a14300f7079440f66c9f/PyMuPDF-1.18.5-cp36-cp36m-manylinux2010_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 3.6MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.18.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06tx6X5vyQHR",
        "outputId": "8969e09a-4633-4ef4-909e-0aeacd2bee4a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')  \n",
        "\n",
        "# change to workying tensorflow directory on the drive\n",
        "%cd '/content/gdrive/MyDrive/'"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymqXXLLOyfMZ"
      },
      "source": [
        "import fitz, sys"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM5wqEvPzQa_",
        "outputId": "f1859e33-8fc8-4aed-c626-9d5d55480452"
      },
      "source": [
        "fname = '/content/Resume-and-CV-Summarization-and-Parsing-with-Spacy-in-Python/Resume.MERN.pdf'\n",
        "doc = fitz.open(fname)\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "  text = text + str(page.getText())\n",
        "text= \"\".join(text.split('\\n'))\n",
        "print(text)\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Asharib Ahmed AI Enthusiast | MERN Stack Developer | DSC Lead | Entrepreneur  H#B-445 Sec#35-A Korangi#04 Karachi, Sindh, Pakistan (+92) 3353011417  asharibahmed143@gmail.com EXPERIENCE AlCodemist, Karachi​ - AI Engineer Jan 2020 - PRESENT AlCodemist is a startup consisting of a group of young entrepreneurs which aims to make technology accessible to those who are less privileged. We are continually striving towards the better and safe future of this world. EDUCATION Sindh Madressatul ISlam University, ​Karachi— ​BSCS September 2018 - March 2020 Bachelors of computer science (5th Semester)  Presidential Initiative for Artificial Intelligence & Computing, Karachi— Course March 2018 - Present Artificial Intelligence Course (Fourth Quarter) PROJECTS Facial Recognition Brain​—​MERN Stack  A MERN Stack web application which does face detection by Clarifai’s Face Detection Model  API. Portfolio ​— ​React It's my portfolio Website base on React with multiple pages rendering   Robo Friend ​— ​React It's simple React base front-end Application which shows a list of robots from an Object  and also provides the searching ability. Samrib Academy​ —UI/UX A responsive Academy front-end application based on bootstrap and PHP. Its contain all the information about Academy’s course faculty and admissions  SMart Brain API​ — ​nodejs/Expressjs It's the back-end of my facial recognition project. It receives http requests and does execution on it and sends back responses . SKILLS Technical Skills​ : Advance Deep Learning, Machine Learning, Computer Vision, Data Analysis, Natural Language Processing, React,  Node.js, Express.js, SQL and Nosql Databases, Python, Javascript, C#. Soft Skills​ : Leadership, Time management, Effective Communication. ACTIVITIES DSC Lead - SMIU ​ June 2020 - present : ​2nd ever lead from SMIU and Pakistani DSC Chapter. YIC Ambassador : ​ Aug 2020 - Present: ​YLC was initiated in 2002, with the identification of an opportunity; the large reserves of energy of Pakistan’s fastest growing youth population.  021 Disrupt Ambassador : ​ Aug 2020 - Present:​ 021Disrupt is Pakistan’s premier entrepreneurship conference showcasing the local startup ecosystem . Microsoft Innovative Educator​ Aug 2020 - present : ​MIE​ ​programs recognize global educator visionaries who are using technology to pave the way for their peers for better learning and student outcomes. LANGUAGES Fluent in English and Urdu. CERTIFICATIONS 14​x Certifications of Deep Learning, Machine Learning, CV, NLP, Tensorflow, Flask, GCP from Coursera , Udemy \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q-xdNiB0JVI",
        "outputId": "1cf11f95-311f-4b27-f83e-2d86b6e999cb"
      },
      "source": [
        "doc = nlp_model(text)\n",
        "for ent in doc.ents:\n",
        "  print(f'{ent.label_.upper():{30}}-{ent.text}')"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME                          -Asharib Ahmed\n",
            "SKILLS                        -Advance Deep Learning, Machine Learning, Computer Vision, Data Analysis, Natural Language Processing, React,\n",
            "COMPANIES WORKED AT           -Microsoft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdfSgYwC06Wh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}